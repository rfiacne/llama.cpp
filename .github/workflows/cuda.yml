# 工作流名称
name: Compile llama.cpp for T4(using CUDA Docker image)

# 触发工作流的事件
on:
  push:
    branches: [ "main", "master" ]
  pull_request:
    branches: [ "main", "master" ]
  workflow_dispatch:

# 工作流中的任务
jobs:
  build-with-specific-image:
    # 关键：使用 GitHub 提供的标准 Ubuntu 运行器，它自带 Docker
    runs-on: ubuntu-latest

    steps:
      # 第一步：检出代码
      - name: Check out repository code
        uses: actions/checkout@v4

      # 第二步：使用指定的 Docker 镜像进行 CPU 编译
      # 注意：我们移除了 --gpus all 标志，因为运行器没有 GPU
      - name: Build llama.cpp for CPU using Docker
        run: |
          docker run --rm -v ${{ github.workspace }}:/app -w /app nvidia/cuda:12.9.1-cudnn-devel-ubuntu22.04 \
          bash -c "apt-get update && apt-get install -y cmake build-essential libcurl4-openssl-dev git && cmake -B build -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=75 && cmake --build build --config Release"


      # 第三步：上传编译产物
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          # 产物的名称
          name: llama-cpp-cpu-build
          # 要上传的文件夹路径
          path: build/
